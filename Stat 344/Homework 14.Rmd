---
title: "Stat 344 -- HW 14"
author: "Trey Tipton"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: 
  pdf_document:
    fig_height: 2.2
    fig_width: 4
  html_document:
    fig_height: 2.2
    fig_width: 4
  word_document:
    fig_height: 2.2
    fig_width: 4
---

```{r, setup, include = FALSE}
# load packages that are going to be used
require(fastR2)   # this loads mosaic, ggformula, etc. too

# Some customization.  You can alter or delete as desired (if you know what you are doing).

theme_set(theme_bw())     # change theme for ggplot2/ggformula

knitr::opts_chunk$set(
  tidy = FALSE,     # display code as typed (rather than reformatted)
  size = "small")   # slightly smaller font for code
```


<!-- Some macros to make mathematics easier -->

\newcommand{\Prob}{\mathrm{P}}
\newcommand{\intersect}{\;\cap\;}
\newcommand{\union}{\operatorname{\cup}}
\newcommand{\E}{\operatorname{E}}
\newcommand{\Var}{\operatorname{Var}}
\newcommand{\SD}{\operatorname{SD}}

<!-- Put your work below here.  Put text in text chunks, code in R chunks. -->

### A. Exploration

```{r}
grateful <- read.csv('https://sldr.netlify.com/data/gratitude-experiment.csv')

gm <- lm(gratitude_score ~ life_rating + group + illness_score, data = grateful)
```


```{r}
gf_point(gratitude_score ~ life_rating, data = grateful) %>%
  gf_labs(title = "Gratitude Score as a function of Life Rating", 
          x = "Life Rating", y = "Gratitude Score")
```

The gratitude score by life rating score appears to be randomly scattered and there does not seem to be a relationship between the two.

```{r}
gf_point(gratitude_score ~ group, data = grateful) %>%
  gf_labs(title = "Gratitude Score by Group", 
          x = "Group", y = "Gratitude Score")
```

The mean of gratitude scores by group appear to go from highest to lowest from gratitude, events, and hassles respectively. The events group also appears to have the largest variance.

```{r}
gf_point(gratitude_score ~ illness_score, data = grateful) %>%
  gf_labs(title = "Gratitude Score as a function of Illness Score", 
          x = "Illness Score", y = "Gratitude Score")
```
  
Similar to the life rating, illness score does not appear to have an effect on the gratitude score as they seem to be randomly scattered.

### Models and R-squared

```{r}
m1 <- lm(gratitude_score ~ 1, data = grateful)
summary(m1)
m2 <- lm(gratitude_score ~ life_rating, data = grateful)
summary(m2)
m3 <- lm(gratitude_score ~ group, data = grateful)
summary(m3)
m4 <- lm(gratitude_score ~ illness_score, data = grateful)
summary(m4)
m5 <- lm(gratitude_score ~ life_rating + group, data = grateful)
summary(m5)
m6 <- lm(gratitude_score ~ life_rating + illness_score, data = grateful)
summary(m6)
m7 <- lm(gratitude_score ~ illness_score + group, data = grateful)
summary(m7)
## gm is m8, the full model
summary(gm)
```

Models 1 through 8 results for $r^2$, adjusted $r^2$.

gratitude_score ~ 1

0, 0

gratitude_score ~ life_rating

0.04243, 0.03749

gratitude_score ~ group

0.1036, 0.0943

gratitude_score ~ illness_score

0.00411, -0.001024

gratitude_score ~ life_rating + group

0.1311, 0.1175

gratitude_score ~ life_rating + illness_score

0.04655, 0.03667

gratitude_score ~ illness_score + group

0.1041, 0.0901

gratitude_score ~ illness_score + group + illness_score

0.132, 0.1138

The highest $r^2$ value is the full model of all three predictors with an $r^2$ of 0.132. However, the highest adjusted $r^2$ is model 5, which includes only life rating and group as predictors for gratitude score with an adjusted $r^2$ of 0.1175.

If presenting results, I would schoose to report the adjusted $r^2$ since we are comparing models with a different number of predictors. The adjusted $r^2$ value takes into account how many predictors the model has, k, while the multiple $r^2$ value does not and gets better if there is simply more predictors. For this reason, I would report the model 5 to be a better $r^2$ than the full model, because it is a higher $r^2$ value when taking into account the number of predictors.

### Model Selection

Approach 1: Backwards Step-wise Selection

```{r}
car::Anova(gm)
```

From the original model, the largest large p-value is generated by illness_score, so we should remove it.
Remove illness_score

```{r}
car::Anova(m5)
```

The remaining p-values are small, so each predictor now plays a significant role in the model.  The best model includes life_rating and group as predictors for gratitude_score, which lines up with what our adjusted $r^2$ value told us earlier.


Approach 2: Forward Selection

```{r}
car::Anova(m1)

car::Anova(m2)

car::Anova(m3)

car::Anova(m4)
```

The smallest small p-value is from m3, the model with only group as a predictor. So we add group as a predictor and try the models with group + other predictors individually.

```{r}
car::Anova(m5)

car::Anova(m7)
```

The next smallest small p-value comes from m5, the model with group and life_rating as predictors. So we should now have group and life_rating as predictors and try the models with those and the other predictors individually. There is only one more predictor to try, which is the original model.

```{r}
car::Anova(gm)
```

Since, illness_score does not have a small p-value, we do not add it to the model. Therefore, the best model is m5 where group and life_rating are predictors of gratitude_score.

Both methods yield the same answer, neither with the full model, meaning that there is reason to remove illness score as a predictor.

I do believe that m5 is the best model. This is the model with life_rating and group are predictors for gratitude_score and illness_score is removed. This appears to be the best model because all three methods to check the goodness of fit for the model yielded m5 as the model, including the adjusted $r^2$ value, backwards step-wise selection, and forward selection. The only method that provided a different answer was the multiple $r^2$ value, which makes sense because it does not account for k number of predictors and gets better for models with more predictors. Therefore, m5 overwhelmingly outperforms the other models and is the overall best model.

Overall, I can conclude that life_rating and group are the best predictors of the gratitude score out of the predictors I chose. However, according to the scatterplots I showed and the relatively low adjusted $r^2$ value from not only the full model but all of them, the relationship does not appear to be overwhelming and I would not say that there is a good linear relationship between gratitude_score and the predictors I chose. The best predictor appears to be group according to the scatter plot and anova p-values, while the worst predictor was illness_score. 



