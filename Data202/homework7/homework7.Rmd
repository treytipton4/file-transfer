---
title: "DATA 202 Homework 7"
author: "Trey Tipton"
date: "`r Sys.Date()`"
output:
  html_document:
    code_download: true
---

```{r setup, include=FALSE}
# Set some useful chunk options for code chunks.
knitr::opts_chunk$set(
  echo = TRUE,
  error = TRUE,    # display errors but keep going.
  comment = "",    # don't add '##' characters before output.
  message = FALSE  # don't include messages in the knitted output (check them in RStudio)
  )

knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidymodels)
library(rpart.plot)
theme_set(theme_bw())
```

```{r load data}
daily_rides <- readRDS(url("https://cs.calvin.edu/courses/info/602/06ensembles/hw/bikeshare-day.rds"))
```

## Exploratory Analytics
```{r}
daily_rides %>%
  select(month, workingday, temp, atemp, casual) %>%
  GGally::ggpairs()
```

```{r}
rides_2011 <- daily_rides %>% filter(year == 2011)
rides_2012 <- daily_rides %>% filter(year == 2012)
```

2012 has 366 observations because 2012 was a leap year, and 2011 was 365 days because it was not a leap year.

```{r}
set.seed(1234)
rides_split <- initial_split(rides_2011, prop = 3/4)
train <- training(rides_split)
test <- testing(rides_split)
```

```{r}
rides_2011_with_split_marked <- bind_rows(
  train = train,
  test = test,
  .id = "split"
) %>% mutate(split = as_factor(split)) %>%
  arrange(date)
rides_2011_with_split_marked %>% head() %>% knitr::kable()
```

```{r}
model_formula <- casual ~ temp + workingday + month
```


Exercise 1: Linear Regression

```{r}
linreg_model <- fit(
  linear_reg(),
  model_formula,
  data = train
)
```

For every additional degree C, the model predicts 24.2 additional rides.

```{r}
linreg_model %>%
  tidy() %>%
  select(term, estimate)
```

Exercise 2: Predictions

```{r}
augment(linreg_model, train) %>%
  ggplot(aes(x = date, y = casual, color = workingday)) +
  geom_point() +
  geom_line(aes(y = .pred))
```

The prediction is not a straight line because the number of riders will increase in the summer and decrease again in the fall.


Exercise 3: Observed By Predicted

```{r}
augment(linreg_model, new_data = train) %>%
  ggplot(aes(x = casual, y = .pred, color = workingday)) +
  geom_abline() +
  geom_point(alpha = .5) +
  coord_obs_pred()
```
 

This model typically predicts too high for weekend dates. It predicts too low for certain weekend and weekday values.

Model debugging strategy

1. The features have high positive values when the prediction is wrong.
2. The target also has high positive numbers when the prediction is wrong.

Exercise 4: Quantify Errors

```{r}
augment(linreg_model, rides_2011_with_split_marked) %>%
  group_by(split) %>%
  #summarize(mae = mean(abs(casual - .pred)))
  mae(truth = casual, estimate = .pred)
```

On days that the model had not seen, the predicted number of rides was higher than expected.

Exercise 5: Decision Tree Regression

```{r}
dtree_model <- fit(
  decision_tree(mode = "regression"),
  model_formula, data = train)
```

```{r}
dtree_model %>%
  extract_fit_engine() %>%
  rpart.plot(roundint = FALSE, digits = 3, type = 4)
```

March 26 2011: The model uses the temperature from the day (which was about 4 degrees) so we go to the left, it was a weekend so we go to the right, and it was March so we go to the right, leading us to 801 casual rides predicted.

Exercise 6

```{r}
augment(dtree_model, new_data = train) %>%
  ggplot(aes(x = casual, y = .pred, color = workingday)) +
  geom_abline() +
  geom_point(alpha = .5) +
  coord_obs_pred()
```

The horizontal lines come from the seven final number of riders from the decision tree.

Exercise 7

```{r}
augment(dtree_model, rides_2011_with_split_marked) %>%
  group_by(split) %>%
  #summarize(mae = mean(abs(casual - .pred)))
  mae(truth = casual, estimate = .pred)
```

The decision tree is a better model based on performance because the metrics are lower.

Ensembles

```{r}
rf_model <-
  rand_forest(mode = "regression") %>%
  fit(model_formula, data = train)
boost_model <- fit(
  boost_tree(mode = "regression"),
  model_formula, data = train)
```

Exercise 8

The split between the test and train data is very different, other than that I do not notice a difference besides the change in function.

```{r}
augment(rf_model, new_data = train) %>%
  ggplot(aes(x = casual, y = .pred, color = workingday)) +
  geom_abline() +
  geom_point(alpha = .5) +
  coord_obs_pred()
```

```{r}
augment(boost_model, new_data = train) %>%
  ggplot(aes(x = casual, y = .pred, color = workingday)) +
  geom_abline() +
  geom_point(alpha = .5) +
  coord_obs_pred()
```

```{r}
# As an aside, here's a way to use a function to represent what's in common between these plots.
# It uses an advanced tidyverse technique: https://dplyr.tidyverse.org/articles/programming.html#indirection
show_obs_vs_pred <- function(model, data, var, ...) {
  augment(model, new_data = data) %>%
    ggplot(aes(x = {{var}}, y = .pred, ...)) +
    geom_abline() +
    geom_point(alpha = .5) +
    coord_obs_pred()
}
show_obs_vs_pred(rf_model, train, casual, color = workingday)
show_obs_vs_pred(boost_model, train, casual, color = workingday)
```

```{r}
eval_dataset <- rides_2011_with_split_marked

all_predictions <- bind_rows(
  linreg_model = augment(linreg_model, new_data = eval_dataset),
  dtree_model = augment(dtree_model, new_data = eval_dataset),
  rf_model = augment(rf_model, new_data = eval_dataset),
  boost_model = augment(boost_model, eval_dataset),
  .id = "model"
) %>% mutate(model = as_factor(model))
```

```{r}
all_predictions %>%
  group_by(model, split) %>%
  mae(truth = casual, estimate = .pred) %>%
  mutate(mae = .estimate) %>%
  ggplot(aes(x = model, y = mae, fill = split)) +
    geom_col(position = "dodge")
```


Exercise 9

The boost_model had the best performance for the training data and the rf_model had the best performance for the unseen data. The linreg_model is underfit, and the boost_model is very overfit.

Exercise 10

```{r}
daily_rides %>% ggplot(aes(x = casual, y = year)) + geom_boxplot()
```


The median was lower for casual riders in 2011 than 2012. The standard deviation for the 2011 number of riders was smaller.

```{r}
eval_dataset <- daily_rides %>%
  mutate(split = year)

all_predictions <- bind_rows(
  linreg_model = augment(linreg_model, new_data = eval_dataset),
  dtree_model = augment(dtree_model, new_data = eval_dataset),
  rf_model = augment(rf_model, new_data = eval_dataset),
  boost_model = augment(boost_model, eval_dataset),
  .id = "model"
) %>% mutate(model = as_factor(model))
```

```{r}
all_predictions %>%
  group_by(model, split) %>%
  mae(truth = casual, estimate = .pred) %>%
  mutate(mae = .estimate) %>%
  ggplot(aes(x = model, y = mae, fill = split)) +
    geom_col(position = "dodge")
```

Exercise 11

```{r}
daily_rides %>% ggplot(aes(x = date, y = casual)) + geom_point() + geom_smooth(method = 'lm')
```

There are more riders in 2012 than predicted from the 2011 data, 2011 had less riders leading to these predictions. Either way, the number of riders is increasing, so the boss should be happy.

